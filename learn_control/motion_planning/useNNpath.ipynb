{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workspace problem with several narrow gaps\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "from io import StringIO\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "import matplotlib.animation as animation\n",
    "import sys\n",
    "import time\n",
    "import cv2\n",
    "from celluloid import Camera\n",
    "from IPython.display import HTML\n",
    "\n",
    "sys.path.append('/home/oscar_palfelt/MSc_thesis/ompl/py-bindings')\n",
    "from ompl import base as ob\n",
    "from ompl import control as oc\n",
    "from ompl import geometric as og\n",
    "\n",
    "rng = default_rng(900)\n",
    "\n",
    "cuda = True\n",
    "DEVICE = torch.device(\"cuda\" if cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load map file\n",
    "\n",
    "filename = '/home/oscar_palfelt/MSc_thesis/EECS_Degree_Project/learn_control/motion_planning/maps/map_parking.png'\n",
    "mapImg = cv2.imread(filename, 0)\n",
    "blurImg = cv2.blur(mapImg, ksize=(3,3))\n",
    "occGrid = np.clip(mapImg, 0, 1)\n",
    "inflatedGrid = np.floor(blurImg / 255)\n",
    "\n",
    "assert occGrid.shape[0] == occGrid.shape[1]\n",
    "gridSize = occGrid.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pytorch networks\n",
    "# based on https://github.com/Jackson-Kang/Pytorch-VAE-tutorial/blob/master/.ipynb_checkpoints/01_Variational_AutoEncoder-checkpoint.ipynb\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim=X_dim+c_dim, hidden_dim=h_Q_dim, latent_dim=z_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.z_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.z_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        seq = self.network(x)\n",
    "\n",
    "        return self.z_mu(seq), self.z_logvar(seq)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=z_dim+c_dim, hidden_dim=h_P_dim, output_dim=X_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return self.network(x)\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, Encoder, Decoder):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.Encoder = Encoder\n",
    "        self.Decoder = Decoder\n",
    "    \n",
    "    def reparameterization(self, mean, logvar):\n",
    "        epsilon = torch.randn_like(mean).to(DEVICE)        # sampling epsilon        \n",
    "        z = mean + torch.exp(0.5 * logvar) * epsilon       # reparameterization trick\n",
    "        return z\n",
    "\n",
    "    def forward(self, x, c, encode=True):\n",
    "        if encode:\n",
    "            z_mu, z_logvar = self.Encoder(torch.cat((x, c), dim=1))\n",
    "            z = self.reparameterization(z_mu, z_logvar)\n",
    "\n",
    "            y = self.Decoder(torch.cat((z, c), dim=1))\n",
    "            \n",
    "            return y, z_mu, z_logvar\n",
    "        else:\n",
    "            z = x\n",
    "            y = self.Decoder(torch.cat((z, c), dim=1))    \n",
    "\n",
    "            return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network parameters\n",
    "mb_size = 256 # mini batch dim\n",
    "h_Q_dim = 512*4 # encoder dim\n",
    "h_P_dim = 512*4 # decoder dim\n",
    "\n",
    "lr = 1e-4 # learning rate\n",
    "\n",
    "# problem dimenc_dimsions\n",
    "nPreviousStates = 1 # number of previous states to condition on the steering prediction\n",
    "dim = 4 # (x, y, yaw, steer)\n",
    "\n",
    "z_dim = 1 # latent dim\n",
    "y_dim = dim # renp.piruction of the original point (unsused?)\n",
    "\n",
    "nDrawnSamples = 10 # number of dependent samples to draw during smapling (length of predicted control series)\n",
    "dataElements = (nDrawnSamples + nPreviousStates) * dim + dim - 1\n",
    "\n",
    "X_dim = nDrawnSamples*dim # steering\n",
    "c_dim = dataElements - X_dim # dimension of conditioning variable\n",
    "\n",
    "network_short = torch.load('/home/oscar_palfelt/MSc_thesis/EECS_Degree_Project/learn_control/networks/stateAndCtrl_park_nonscaled_10short.pt')\n",
    "\n",
    "nDrawnSamples = 20 # number of dependent samples to draw during smapling (length of predicted control series)\n",
    "dataElements = (nDrawnSamples + nPreviousStates) * dim + dim - 1\n",
    "\n",
    "X_dim = nDrawnSamples*dim # steering\n",
    "c_dim = dataElements - X_dim # dimension of conditioning variable\n",
    "\n",
    "network_long = torch.load('/home/oscar_palfelt/MSc_thesis/EECS_Degree_Project/learn_control/networks/stateAndCtrl_park_nonscaled_20long.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84250, 87)\n"
     ]
    }
   ],
   "source": [
    "# read in data from .txt file, re-arrange to allow drawing multiple depedent samples\n",
    "\n",
    "filename = '/home/oscar_palfelt/MSc_thesis/EECS_Degree_Project/learn_control/motion_planning/data/ctrlDataPfollowPark_18000plans'\n",
    "rawdata = np.genfromtxt(filename, delimiter=',', dtype='d', usecols=[0,1,2,3,7,8,9]) # disregard init\n",
    "\n",
    "_, pathsIdx = np.unique(rawdata[:,4:], axis=0, return_index=True)\n",
    "pathsIdx.sort()\n",
    "\n",
    "pathsLengths = np.roll(pathsIdx, -1) - pathsIdx\n",
    "pathsLengths[-1] = rawdata.shape[0] - np.sum(pathsLengths[:-1])\n",
    "\n",
    "validLengthsIdx = np.argwhere(pathsLengths >= nPreviousStates + nDrawnSamples) \n",
    "validPlansIdx = pathsIdx[validLengthsIdx]\n",
    "\n",
    "data = np.zeros(shape=(1, dataElements)) # steering angles, samples (x,y,yaw), goal(x,y,yaw)\n",
    "tempdata = np.copy(data) # steering angles, samples (x,y,yaw), goal(x,y,yaw)\n",
    "for ci, i in enumerate(validPlansIdx.reshape(-1)):\n",
    "    #rawdata[i:i+pathsLenghts[ci], dim-1] = uniform_filter1d(rawdata[i:i+pathsLenghts[ci], dim-1], size=1, origin=0, mode='nearest', axis=0) # average over steering\n",
    "    for j in range(pathsLengths[ci] - (nPreviousStates + nDrawnSamples - 1)):\n",
    "        sample = np.arange(start=j, stop=j + nPreviousStates + nDrawnSamples)\n",
    "\n",
    "        if np.any(np.abs(np.diff(rawdata[i + sample, 0])) > 0.05) or np.any(np.abs(np.diff(rawdata[i + sample, 1])) > 0.05):\n",
    "            break # ignore duplicate plans (data generation is not perfect)\n",
    "\n",
    "        tempdata = np.vstack((tempdata, np.append(rawdata[i + sample, :dim].reshape(1, (nPreviousStates + nDrawnSamples)*dim), rawdata[i, dim:].reshape(1, dim-1), axis=1))) \n",
    "        if ci % 500 == 0:\n",
    "            data = np.vstack((data, tempdata[1:]))\n",
    "            tempdata = np.zeros(shape=(1, dataElements))\n",
    "\n",
    "rng.shuffle(data) # shuffle data\n",
    "\n",
    "numEntries = data.shape[0]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VehicleState():\n",
    "    def __init__(self):\n",
    "        self.x = 0\n",
    "        self.y = 0\n",
    "        self.yaw = 0\n",
    "        self.v = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate planning scenario, plan, and perform path following\n",
    "\n",
    "goalDistThreshold = 0.1 # distance to goal when motion execution no longer performed\n",
    "nLatSamples = 1000 # number of samples to draw in latent space (when using nn)\n",
    "p = 0.8 # likelihood which to sample from NN samples (when useNN is True)\n",
    "maxCtrlIter = 140\n",
    "\n",
    "dt = 0.1 # controller time step\n",
    "L = 0.2 # vehicle length constant\n",
    "v =  0.1 # vehicle speed\n",
    "\n",
    "pathIdx = np.random.randint(0, numEntries - 1) # 95321\n",
    "start = data[pathIdx, :dim]\n",
    "goal = data[pathIdx, -dim+1:]\n",
    "\n",
    "# start = np.array([29/30, 28/30, -np.pi, 0.])\n",
    "# goal = np.array([2/30, 1/30, -np.pi])\n",
    "\n",
    "state = VehicleState()\n",
    "\n",
    "state.x = start[0]; state.y = start[1]; state.yaw = start[2]; state.v = v\n",
    "statelist = [[state.x, state.y, state.yaw, 0]]\n",
    "\n",
    "maxSteer = np.max(data[:, 3::dim])\n",
    "minSteer = np.min(data[:, 3::dim])\n",
    "steerAngles = np.linspace(minSteer, maxSteer, num=200)\n",
    "delta = 0\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,8), gridspec_kw={'width_ratios': [3, 2]})\n",
    "camera = Camera(fig)\n",
    "\n",
    "ctrliter = 0\n",
    "while ctrliter < maxCtrlIter:\n",
    "    currentState = np.array(statelist[-1])\n",
    "\n",
    "    c = torch.from_numpy(np.repeat([np.append(currentState, goal)], nLatSamples, axis=0)).float().to(DEVICE)\n",
    "    if np.linalg.norm(currentState[:-2] - goal[:-1]) < 0.42:\n",
    "        predictedStates = network_short(torch.randn(nLatSamples, z_dim).to(DEVICE), c, encode=False).cpu().detach().numpy()\n",
    "    else:\n",
    "        predictedStates = network_long(torch.randn(nLatSamples, z_dim).to(DEVICE), c, encode=False).cpu().detach().numpy()\n",
    "\n",
    "    kdes = np.array([gaussian_kde(predictedStates[:, i * dim - 1]) for i in range(1, 2)])\n",
    "    delta = np.mean(steerAngles[[np.argmax(kde.pdf(steerAngles)) for kde in kdes]])\n",
    "\n",
    "    ax1.scatter(predictedStates[:,::dim] * gridSize, predictedStates[:,1::dim] * gridSize, color='green', s=70, alpha=0.01) # nn samples\n",
    "    ax1.quiver(currentState[0] * gridSize, currentState[1] * gridSize, np.cos(currentState[2]), np.sin(currentState[2]), color='red', scale=8.0, width=0.015)\n",
    "    ax1.quiver(goal[0] * gridSize, goal[1] * gridSize, np. cos(goal[2]), np.sin(goal[2]), color='blue', scale=8.0, width=0.015)\n",
    "    ax1.imshow(mapImg, extent=[0, gridSize, 0, gridSize], cmap='gray')\n",
    "    # ax1.set_xlim([-1, gridSize + 1])\n",
    "    # ax1.set_xlim([-1, gridSize + 1])\n",
    "    ax1.set_xlabel('x', fontsize=12)\n",
    "    ax1.set_ylabel('y', fontsize=12)\n",
    "    ax2.plot(steerAngles, kdes[0].pdf(steerAngles), color='C0')\n",
    "    ax2.set_xlabel('Steering angle', fontsize=12)\n",
    "    ax2.set_ylabel('Sample density', fontsize=12)\n",
    "    camera.snap()\n",
    "\n",
    "    state.x += v * np.cos(state.yaw) * dt\n",
    "    state.y += v * np.sin(state.yaw) * dt\n",
    "    state.yaw += v / L * np.tan(delta) * dt\n",
    "    state.v = v - np.clip(np.abs(delta), 0, v / 2)\n",
    "\n",
    "    statelist.append([state.x, state.y, state.yaw, delta])\n",
    "    ctrliter += 1\n",
    "    \n",
    "    if np.linalg.norm(currentState[:-2] - goal[:-1]) < goalDistThreshold:\n",
    "        break\n",
    "\n",
    "print(ctrliter)\n",
    "fps = 10\n",
    "animation = camera.animate(interval=1000/fps)\n",
    "print(\"saving animation\")\n",
    "animation.save('animation.mp4')\n",
    "\n",
    "# nSteps = len(statelist)\n",
    "# statearr = np.array(statelist).reshape(-1).reshape(nSteps, dim)\n",
    "\n",
    "# fig1 = plt.figure(figsize=(10,6), dpi=80)\n",
    "# ax1 = fig1.add_subplot(111, aspect='equal')\n",
    "# ax1.quiver(start[0] * gridSize, start[1] * gridSize, np.cos(start[2]), np.sin(start[2]), color=\"red\", scale=8.0, width=0.015) # init\n",
    "# ax1.quiver(goal[0] * gridSize, goal[1] * gridSize, np.cos(goal[2]), np.sin(goal[2]), color=\"blue\", scale=8.0, width=0.015) # goal\n",
    "# ax1.quiver(statearr[:,0] * gridSize, statearr[:,1] * gridSize, np.cos(statearr[:,2]), np.sin(statearr[:,2]), color='purple', scale=16.0, width=0.01)\n",
    "# ax1.imshow(occGrid, extent=[0, gridSize, 0, gridSize], cmap='gray')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.579811  0.119888 -2.869749]\n"
     ]
    }
   ],
   "source": [
    "print(goal)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9e6cc1179d3ed6ae143ff3dc9ac563dc8e696a51d4136aae17def4ab6c30aa1f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('project_env_3_8': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
