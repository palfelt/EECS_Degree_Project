{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules import loss\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from scipy.cluster.vq import whiten, kmeans, kmeans2\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "rng = default_rng()\n",
    "\n",
    "cuda = True\n",
    "DEVICE = torch.device(\"cuda\" if cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network parameters\n",
    "mb_size = 256 # mini batch dim\n",
    "h_Q_dim = 512*4 # encoder dim\n",
    "h_P_dim = 512*4 # decoder dim\n",
    "\n",
    "lr = 1e-4 # learning rate\n",
    "\n",
    "# problem dimenc_dimsions\n",
    "nDrawnSamples = 10 # number of dependent samples to draw during smapling (length of predicted control series)\n",
    "nPreviousStates = 1 # number of previous states to condition on the steering prediction\n",
    "dim = 4 # (x, y, yaw, steer)\n",
    "#dataElements = nDrawnSamples + 2 * (dim - 1) # steer sample, current pose (3D: x,y,yaw), goal (3D)\n",
    "dataElements = (nDrawnSamples + nPreviousStates) * dim + dim - 1\n",
    "\n",
    "z_dim = 2 # latent dim\n",
    "X_dim = nDrawnSamples*dim # steering\n",
    "y_dim = dim # renp.piruction of the original point (unsused?)\n",
    "c_dim = dataElements - X_dim # dimension of conditioning variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load map file\n",
    "\n",
    "filename = '/home/oscar_palfelt/MSc_thesis/EECS_Degree_Project/learn_control/motion_planning/maps/map_difficult.png'\n",
    "mapImg = cv2.imread(filename, 0)\n",
    "blurImg = cv2.blur(mapImg, ksize=(3,3))\n",
    "occGrid = np.clip(mapImg, 0, 1)\n",
    "inflatedGrid = np.floor(blurImg / 255)\n",
    "\n",
    "assert occGrid.shape[0] == occGrid.shape[1]\n",
    "gridSize = occGrid.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data from .txt file, re-arrange to allow drawing multiple depedent samples\n",
    "\n",
    "filename = '/home/oscar_palfelt/MSc_thesis/EECS_Degree_Project/learn_control/motion_planning/data/ctrlDataPfollow'\n",
    "rawdata = np.genfromtxt(filename, delimiter=',', dtype='d', usecols=[0,1,2,3,7,8,9]) # disregard init\n",
    "\n",
    "_, pathsIdx = np.unique(rawdata[:,4:], axis=0, return_index=True)\n",
    "pathsIdx.sort()\n",
    "\n",
    "pathsLengths = np.roll(pathsIdx, -1) - pathsIdx\n",
    "pathsLengths[-1] = rawdata.shape[0] - np.sum(pathsLengths[:-1])\n",
    "\n",
    "validLengthsIdx = np.argwhere(pathsLengths >= nPreviousStates + nDrawnSamples) \n",
    "validPlansIdx = pathsIdx[validLengthsIdx]\n",
    "\n",
    "data = np.zeros(shape=(1, dataElements)) # steering angles, samples (x,y,yaw), goal(x,y,yaw)\n",
    "tempdata = np.copy(data) # steering angles, samples (x,y,yaw), goal(x,y,yaw)\n",
    "for ci, i in enumerate(validPlansIdx.reshape(-1)):\n",
    "    #rawdata[i:i+pathsLenghts[ci], dim-1] = uniform_filter1d(rawdata[i:i+pathsLenghts[ci], dim-1], size=1, origin=0, mode='nearest', axis=0) # average over steering\n",
    "    for j in range(pathsLengths[ci] - (nPreviousStates + nDrawnSamples - 1)):\n",
    "        sample = np.arange(start=j, stop=j + nPreviousStates + nDrawnSamples)\n",
    "\n",
    "        if np.any(np.abs(np.diff(rawdata[i + sample, 0])) > 0.05) or np.any(np.abs(np.diff(rawdata[i + sample, 1])) > 0.05):\n",
    "            break # ignore duplicate plans (data generation is not perfect)\n",
    "\n",
    "        tempdata = np.vstack((tempdata, np.append(rawdata[i + sample, :dim].reshape(1, (nPreviousStates + nDrawnSamples)*dim), rawdata[i, dim:].reshape(1, dim-1), axis=1))) \n",
    "        if ci % 500 == 0:\n",
    "            data = np.vstack((data, tempdata[1:]))\n",
    "            tempdata = np.zeros(shape=(1, dataElements))\n",
    "\n",
    "rng.shuffle(data) # shuffle data\n",
    "dataNonscaled = np.copy(data)\n",
    "data[:, dim-2::dim] /= np.max(np.abs(data[:, dim-2::dim]),axis=0) # normalize yaw angles to [-1, 1]\n",
    "data[:, dim-1::dim] /= np.max(np.abs(data[:, dim-1::dim]),axis=0) # normalzie steering angles to [-1, 1]\n",
    "\n",
    "step = 1\n",
    "assert np.floor(nDrawnSamples / step) > 0\n",
    "keepCol = np.concatenate((np.arange(dim*nPreviousStates), \n",
    "                            np.array([np.arange(start=j*dim*step, stop=dim*(1 + step*j) ) for j in range(1, 1 + np.floor(nDrawnSamples / step).astype(int))]).reshape(-1), \n",
    "                            np.arange(dataElements - dim + 1, dataElements))) # keep previous states, step next states, and goal\n",
    "\n",
    "X_dim = nDrawnSamples*dim - (dataElements - keepCol.shape[0])\n",
    "data = data[1:, keepCol]\n",
    "\n",
    "numEntries = data.shape[0]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = np.random.randint(1,numEntries)\n",
    "plt.imshow(mapImg, extent=[0, gridSize, 0, gridSize], cmap='gray')\n",
    "plt.scatter(data[i, :-dim:dim] * gridSize, data[i, 1:-dim:dim] * gridSize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(365806, 40)\n"
     ]
    }
   ],
   "source": [
    "# split the inputs and conditions into test train (to be processed in the next step into an occupancy grid representation)\n",
    "\n",
    "ratioTestTrain = 0.8;\n",
    "numTrain = int(numEntries*ratioTestTrain)\n",
    "\n",
    "X_train = data[0:numTrain, dim * nPreviousStates:-dim+1:] # states [x,y,yaw,steer] to predict\n",
    "X_test = data[numTrain:numEntries, dim * nPreviousStates:-dim+1:]\n",
    "\n",
    "numTest = X_test.shape[0]\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(457258, 7)\n"
     ]
    }
   ],
   "source": [
    "# generate conditioning variable\n",
    "\n",
    "prevStatesNonscaled = dataNonscaled[1:, keepCol][:, :nPreviousStates*dim]\n",
    "nextStatesNonscaled = dataNonscaled[1:, keepCol][:, nPreviousStates*dim:-dim+1]\n",
    "nextStates = data[:, nPreviousStates*dim:-dim+1]\n",
    "goalStateNonscaled = dataNonscaled[1:, keepCol][:, -dim+1:]\n",
    "\n",
    "prevStatesConditions = data[:, :nPreviousStates * dim]\n",
    "goalStateCondition = data[:, -dim+1:]\n",
    "\n",
    "cs = np.concatenate((prevStatesConditions, goalStateCondition), axis=1)\n",
    "\n",
    "c_dim = cs.shape[1]\n",
    "c_train = cs[0:numTrain,:]  \n",
    "c_test = cs[numTrain:numEntries,:]\n",
    "\n",
    "print(cs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pytorch networks\n",
    "# based on https://github.com/Jackson-Kang/Pytorch-VAE-tutorial/blob/master/.ipynb_checkpoints/01_Variational_AutoEncoder-checkpoint.ipynb\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim=X_dim+c_dim, hidden_dim=h_Q_dim, latent_dim=z_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.z_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.z_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        seq = self.network(x)\n",
    "\n",
    "        return self.z_mu(seq), self.z_logvar(seq)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=z_dim+c_dim, hidden_dim=h_P_dim, output_dim=X_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return self.network(x)\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, Encoder, Decoder):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.Encoder = Encoder\n",
    "        self.Decoder = Decoder\n",
    "    \n",
    "    def reparameterization(self, mean, logvar):\n",
    "        epsilon = torch.randn_like(mean).to(DEVICE)        # sampling epsilon        \n",
    "        z = mean + torch.exp(0.5 * logvar) * epsilon       # reparameterization trick\n",
    "        return z\n",
    "\n",
    "    def forward(self, x, c, encode=True):\n",
    "        if encode:\n",
    "            z_mu, z_logvar = self.Encoder(torch.cat((x, c), dim=1))\n",
    "            z = self.reparameterization(z_mu, z_logvar)\n",
    "\n",
    "            y = self.Decoder(torch.cat((z, c), dim=1))\n",
    "            \n",
    "            return y, z_mu, z_logvar\n",
    "        else:\n",
    "            z = x\n",
    "            y = self.Decoder(torch.cat((z, c), dim=1))    \n",
    "\n",
    "            return y\n",
    "\n",
    "\n",
    "encoder = Encoder()\n",
    "decoder = Decoder()\n",
    "network = NeuralNetwork(Encoder=encoder, Decoder=decoder).to(DEVICE)\n",
    "\n",
    "def loss_function(x, y, mean, logvar):\n",
    "    recon_loss = ((x - y) ** 2).mean()\n",
    "    kl_loss    = 10**-4 * 2 * torch.sum(torch.exp(logvar) + mean.pow(2) - 1. - logvar, dim=1)\n",
    "\n",
    "    return torch.mean(kl_loss + recon_loss)\n",
    "\n",
    "optimizer = optim.Adam(network.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "for it in range(180001):\n",
    "    # randomly generate batches\n",
    "    batch_elements = [np.random.randint(0,numTrain-1) for n in range(0,mb_size)]\n",
    "\n",
    "    X_mb = torch.tensor(X_train[batch_elements,:], requires_grad=True, dtype=torch.float32, device=DEVICE)\n",
    "    c_mb = torch.tensor(c_train[batch_elements,:], requires_grad=True, dtype=torch.float32, device=DEVICE)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    y, z_mu, z_logvar = network(X_mb, c_mb)\n",
    "    \n",
    "    loss = loss_function(X_mb, y, z_mu, z_logvar)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if it % 1000 == 0:\n",
    "        batch_elements = [np.random.randint(0,numTest-1) for n in range(0,mb_size)]\n",
    "\n",
    "        Xval_mb = torch.tensor(X_test[batch_elements,:], requires_grad=False, dtype=torch.float32, device=DEVICE)\n",
    "        cval_mb = torch.tensor(c_test[batch_elements,:], requires_grad=False, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "        yval, z_muval, z_logvarval = network(Xval_mb, cval_mb)\n",
    "\n",
    "        valloss = loss_function(Xval_mb, yval, z_muval, z_logvarval)\n",
    "\n",
    "        print('Iter: {}'.format(it))\n",
    "        print('Loss: {:.4}'. format(loss))\n",
    "        print('VLoss: {:.4} \\n'. format(valloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the latent space\n",
    "num_viz = 800 # number of samples to draw in latent space\n",
    "vizIdx = np.random.randint(0,numTest-1); # chose a random test scenario\n",
    "c_sample_seed = c_test[vizIdx,:]\n",
    "c_sample = torch.from_numpy(np.repeat([c_sample_seed],num_viz,axis=0)).float().to(DEVICE)\n",
    "\n",
    "y_viz = network(torch.randn(num_viz, z_dim).to(DEVICE), c_sample, encode=False).cpu().detach().numpy() # y_viz is sample in state space, zviz in latent space (3D)\n",
    "t = np.tile(np.arange(nDrawnSamples, step=step), reps=(num_viz, 1)) * 0.05\n",
    "\n",
    "\n",
    "xPrev = prevStatesNonscaled[numTrain + vizIdx, ::dim]\n",
    "yPrev = prevStatesNonscaled[numTrain + vizIdx, 1::dim]\n",
    "yawPrev = prevStatesNonscaled[numTrain + vizIdx, 2::dim]\n",
    "steerPrev = prevStatesConditions[numTrain + vizIdx, 3::dim]\n",
    "\n",
    "xNext = nextStatesNonscaled[numTrain + vizIdx, ::dim]\n",
    "yNext = nextStatesNonscaled[numTrain + vizIdx, 1::dim]\n",
    "steerNext = nextStates[numTrain + vizIdx, 3::dim]\n",
    "\n",
    "plt.scatter(y_viz[:num_viz//3,::dim] * gridSize, y_viz[:num_viz//3,1::dim] * gridSize, color='green', s=70, alpha=0.01) # nn samples\n",
    "plt.scatter(xNext * gridSize, yNext * gridSize, color='purple') # true next poses\n",
    "plt.quiver(xPrev[-1] * gridSize, yPrev[-1] * gridSize, np.cos(yawPrev[-1]), np.sin(yawPrev[-1]), color='red', scale=8.0, width=0.015) # current pose\n",
    "plt.quiver(goalStateNonscaled[numTrain + vizIdx, 0] * gridSize, goalStateNonscaled[numTrain + vizIdx, 1] * gridSize, np.cos(goalStateNonscaled[numTrain + vizIdx, 2]), np.sin(goalStateNonscaled[numTrain + vizIdx, 2]), color=\"blue\", scale=8.0, width=0.015) # goal\n",
    "plt.imshow(mapImg, extent=[0, gridSize, 0, gridSize], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(t, y_viz[:, 3::dim], alpha=0.01)\n",
    "plt.scatter(t[0], steerNext, alpha = 0.5)\n",
    "plt.scatter(np.arange(-nPreviousStates, 0) * 0.05, steerPrev)\n",
    "plt.ylim([-1.,1.])\n",
    "plt.legend(['Predict', 'True', 'Previous'])\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('Steering')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(network, \"/home/oscar_palfelt/MSc_thesis/EECS_Degree_Project/learn_distributions/CVAE_difficult_steering.pt\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9e6cc1179d3ed6ae143ff3dc9ac563dc8e696a51d4136aae17def4ab6c30aa1f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('project_env_3_8': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
