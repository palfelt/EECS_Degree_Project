{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Workspace problem with several narrow gaps\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import cKDTree as KDTree\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.append('/home/oscar_palfelt/MSc_thesis/ompl/py-bindings')\n",
    "from ompl import base as ob\n",
    "from ompl import control as oc\n",
    "from ompl import geometric as og\n",
    "\n",
    "cuda = False\n",
    "DEVICE = torch.device(\"cuda\" if cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# neural network parameters\n",
    "mb_size = 256 # mini batch dim\n",
    "h_Q_dim = 512 # encoder dim\n",
    "h_P_dim = 512 # decoder dim\n",
    "\n",
    "# problem dimenc_dimsions\n",
    "dim = 4 # (x, y, xdot, ydot)\n",
    "dataElements = dim+3*3+2*dim # sample (4D), gap1 (2D, 1D orientation), gap2, gap3, init (4D), goal (4D)\n",
    "\n",
    "z_dim = 2 # latent dim\n",
    "X_dim = dim # samples dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in data\n",
    "# data from https://github.com/StanfordASL/LearnedSamplingDistributions\n",
    "filename = '/home/oscar_palfelt/MSc_thesis/LearnedSamplingDistributions/narrowDataFile.txt'\n",
    "data = np.genfromtxt(filename, delimiter=',', dtype='d', usecols=[0,1,3,4,6,7,8,9,10,11,12,13,14,15,16,18,19,21,22,24,25])\n",
    "numEntries = data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change conditions to occupancy grid\n",
    "# code from https://github.com/StanfordASL/LearnedSamplingDistributions\n",
    "\n",
    "def isSampleFree(sample, obs):\n",
    "    for o in list(range(0,obs.shape[0]//(2*dimW))): # python 2 -> 3: use list(), use //\n",
    "        isFree = 0\n",
    "        for d in range(0,sample.shape[0]):\n",
    "            if (sample[d] < obs[2*dimW*o + d] or sample[d] > obs[2*dimW*o + d + dimW]):\n",
    "                isFree = 1\n",
    "                break\n",
    "        if isFree == 0:\n",
    "            return 0\n",
    "    return 1\n",
    "\n",
    "gridSize = 11\n",
    "dimW = 3\n",
    "plotOn = False;\n",
    "\n",
    "# process data into occupancy grid\n",
    "conditions = data[0:numEntries,dim:dataElements]\n",
    "conditionsOcc = np.zeros([numEntries,gridSize*gridSize])\n",
    "occGridSamples = np.zeros([gridSize*gridSize, 2])\n",
    "gridPointsRange = np.linspace(0,1,num=gridSize)\n",
    "\n",
    "idx = 0;\n",
    "for i in gridPointsRange:\n",
    "    for j in gridPointsRange:\n",
    "        occGridSamples[idx,0] = i\n",
    "        occGridSamples[idx,1] = j\n",
    "        idx += 1;\n",
    "\n",
    "for j in range(0,numEntries,1):\n",
    "    dw = 0.1\n",
    "    dimW = 3\n",
    "    gap1 = conditions[j,0:3]\n",
    "    gap2 = conditions[j,3:6]\n",
    "    gap3 = conditions[j,6:9]\n",
    "\n",
    "    obs1 = [0, gap1[1]-dw, -0.5,             gap1[0], gap1[1], 1.5]\n",
    "    obs2 = [gap2[0]-dw, 0, -0.5,             gap2[0], gap2[1], 1.5];\n",
    "    obs3 = [gap2[0]-dw, gap2[1]+dw, -0.5,    gap2[0], 1, 1.5];\n",
    "    obs4 = [gap1[0]+dw, gap1[1]-dw, -0.5,    gap3[0], gap1[1], 1.5];\n",
    "    obs5 = [gap3[0]+dw, gap1[1]-dw, -0.5,    1, gap1[1], 1.5];\n",
    "    obs = np.concatenate((obs1, obs2, obs3, obs4, obs5), axis=0)\n",
    "    \n",
    "    if j % 5000 == 0:\n",
    "        print('Iter: {}'.format(j))\n",
    "        \n",
    "    occGrid = np.zeros(gridSize*gridSize)\n",
    "    for i in range(0,gridSize*gridSize):\n",
    "        occGrid[i] = isSampleFree(occGridSamples[i,:],obs)\n",
    "    conditionsOcc[j,:] = occGrid\n",
    "    \n",
    "cs = np.concatenate((data[0:numEntries,dim+3*dimW:dataElements], conditionsOcc), axis=1) # occ(11x11), init (4D), goal (4D)\n",
    "c_dim = cs.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pytorch networks\n",
    "# based on https://github.com/Jackson-Kang/Pytorch-VAE-tutorial/blob/master/.ipynb_checkpoints/01_Variational_AutoEncoder-checkpoint.ipynb\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim=X_dim+c_dim, hidden_dim=h_Q_dim, latent_dim=z_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.z_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.z_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        seq = self.network(x)\n",
    "\n",
    "        return self.z_mu(seq), self.z_logvar(seq)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=z_dim+c_dim, hidden_dim=h_P_dim, output_dim=X_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return self.network(x)\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, Encoder, Decoder):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.Encoder = Encoder\n",
    "        self.Decoder = Decoder\n",
    "    \n",
    "    def reparameterization(self, mean, logvar):\n",
    "        epsilon = torch.randn_like(mean).to(DEVICE)        # sampling epsilon        \n",
    "        z = mean + torch.exp(0.5 * logvar) * epsilon       # reparameterization trick\n",
    "        return z\n",
    "\n",
    "    def forward(self, x, c, encode=True):\n",
    "        if encode:\n",
    "            z_mu, z_logvar = self.Encoder(torch.cat((x, c), dim=1))\n",
    "            z = self.reparameterization(z_mu, z_logvar)\n",
    "\n",
    "            y = self.Decoder(torch.cat((z, c), dim=1))\n",
    "            \n",
    "            return y, z_mu, z_logvar\n",
    "        else:\n",
    "            z = x\n",
    "            y = self.Decoder(torch.cat((z, c), dim=1))    \n",
    "\n",
    "            return y\n",
    "\n",
    "network = torch.load('/home/oscar_palfelt/MSc_thesis/EECS_Degree_Project/learn_distributions/network_name.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define planning problem\n",
    "\n",
    "def getThresholdPathLengthObj(si):\n",
    "     obj = ob.PathLengthOptimizationObjective(si)\n",
    "     obj.setCostThreshold(ob.Cost(2.0))\n",
    "     return obj\n",
    "\n",
    "\n",
    "class MyStateSampler(ob.StateSampler):\n",
    "    def __init__(self, space):\n",
    "         super(MyStateSampler, self).__init__(space)\n",
    "         self.name_ = \"my sampler\"\n",
    "         self.bounds = space.getBounds()\n",
    "\n",
    "    def sampleUniform(self, state):\n",
    "        if np.random.uniform() < p:\n",
    "            rndState = y[np.random.randint(low=0, high=y.shape[0]-1), :]\n",
    "            state.setYaw(float(int(rndState[3] > 0) * np.arccos(np.dot(rndState[2:4] / np.linalg.norm(rndState[2:4]), [1, 0])))) # this is wrong\n",
    "        else:\n",
    "            rndState = [np.random.uniform(low=self.bounds.low[0], high=self.bounds.high[0]),\n",
    "                        np.random.uniform(low=self.bounds.low[1], high=self.bounds.high[1]),\n",
    "                        np.random.uniform(low=-np.pi, high=np.pi)]\n",
    "            state.setYaw(rndState[2])\n",
    "\n",
    "        state.setX(float(rndState[0]))\n",
    "        state.setY(float(rndState[1]))\n",
    "\n",
    "\n",
    "def allocStateSampler(space):\n",
    "    return MyStateSampler(space)\n",
    "\n",
    "\n",
    "def isStateValid(spaceInformation, state):\n",
    "    # perform collision checking or check if other constraints are\n",
    "    # satisfied\n",
    "    u = int(np.floor(state.getX() * occGrid.shape[1])) # right pointing image axis\n",
    "    v = int(np.floor(occGrid.shape[0] * (1 - state.getY()))) # down pointing image axis\n",
    "\n",
    "    if spaceInformation.satisfiesBounds(state):\n",
    "        return occGrid[v,u] > 0\n",
    "\n",
    "\n",
    "def problemDef():\n",
    "    # construct the state space we are planning in\n",
    "    space = ob.DubinsStateSpace(turningRadius=0.1)\n",
    "\n",
    "    # set the bounds for the R^2 part of SE(2)\n",
    "    bounds = ob.RealVectorBounds(2)\n",
    "    bounds.setLow(0.001)\n",
    "    bounds.setHigh(0.999)\n",
    "    space.setBounds(bounds)\n",
    "\n",
    "    # set state sampler\n",
    "    space.setStateSamplerAllocator(ob.StateSamplerAllocator(allocStateSampler))\n",
    "\n",
    "    # define a simple setup class\n",
    "    ss = og.SimpleSetup(space)\n",
    "    ss.setStateValidityChecker(ob.StateValidityCheckerFn( \\\n",
    "        partial(isStateValid, ss.getSpaceInformation())))\n",
    "\n",
    "    si = ss.getSpaceInformation()\n",
    "    planner = og.RRTstar(si)\n",
    "    ss.setPlanner(planner)\n",
    "\n",
    "    ss.getProblemDefinition().setOptimizationObjective(getThresholdPathLengthObj(si))\n",
    "    \n",
    "    return ss\n",
    "\n",
    "\n",
    "def plan(planObj, initState, goalState):\n",
    "\n",
    "    space = ob.DubinsStateSpace(turningRadius=0.1)\n",
    "    \n",
    "    start = ob.State(space)\n",
    "    start().setX(initState[0])\n",
    "    start().setY(initState[1])\n",
    "    start().setYaw(initState[2])\n",
    "\n",
    "    goal = ob.State(space)\n",
    "    goal().setX(goalState[0])\n",
    "    goal().setY(goalState[1])\n",
    "    goal().setYaw(goalState[2])\n",
    "    \n",
    "    planObj.setStartAndGoalStates(start, goal, 0.1)\n",
    "\n",
    "    timeTerminationCondition = ob.timedPlannerTerminationCondition(5.0)\n",
    "    exactSolTerminationCondition = ob.exactSolnPlannerTerminationCondition(planObj.getProblemDefinition())\n",
    "\n",
    "    planObj.solve(ob.plannerOrTerminationCondition(exactSolTerminationCondition, timeTerminationCondition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare performance of planning w/ and w/out the learned distributions\n",
    "\n",
    "nTests = 1\n",
    "\n",
    "nSamples = 2000 # number of samples to draw in latent space\n",
    "\n",
    "planObj = problemDef()\n",
    "minCostThreshold = 0.0 # set minimumcost threshold to only attempt complex planning scenarios\n",
    "\n",
    "nTotIterations = np.array([0, 0])\n",
    "nCompletedTests = 0\n",
    "\n",
    "plotPaths = True\n",
    "while nCompletedTests <= nTests - 1:\n",
    "\n",
    "    planIdx = np.random.randint(0,numEntries-1); # chose a random test scenario\n",
    "\n",
    "    c_sample_seed = cs[planIdx,:]\n",
    "    c_sample = torch.from_numpy(np.repeat([c_sample_seed],nSamples,axis=0)).float().to(DEVICE)\n",
    "\n",
    "    # generate state space samples from the CVAE\n",
    "    y = network(torch.randn(nSamples, z_dim).to(DEVICE), c_sample, encode=False).cpu().detach().numpy()\n",
    "\n",
    "    start = data[planIdx, 13:16]\n",
    "    goal = data[planIdx, 17:20]\n",
    "    # the start/goal yaw is constant 0 which might not be suitable. For improvement, the initial/goal yaw should be determined\n",
    "        \n",
    "    occGrid = np.rot90(c_sample_seed[-gridSize*gridSize:].reshape(gridSize, gridSize))\n",
    "\n",
    "    nIterations = np.array([0, 0])\n",
    "    for i, p in enumerate([0., 0.6]): # p is probability of using the NN during sampling\n",
    "        planObj.clear()\n",
    "        plan(planObj, initState=start, goalState=goal)\n",
    "\n",
    "        if planObj.getProblemDefinition().hasExactSolution():\n",
    "            if planObj.getPlanner().bestCost().value() > minCostThreshold:\n",
    "                sol = np.loadtxt(StringIO(planObj.getProblemDefinition().getSolutionPath().printAsMatrix()))\n",
    "                nIterations[i] += planObj.getPlanner().numIterations()\n",
    "                \n",
    "                if plotPaths:\n",
    "                    fig1 = plt.figure(figsize=(10,6), dpi=80)\n",
    "                    ax1 = fig1.add_subplot(111, aspect='equal')\n",
    "                    ax1.imshow(occGrid, extent=[0, gridSize-1, 0, gridSize-1], cmap='gray')\n",
    "                    ax1.scatter(y[:,0] * (gridSize - 1), y[:,1] * (gridSize - 1), color=\"green\", s=70, alpha=0.1)\n",
    "                    ax1.quiver(sol[:, 0] * (gridSize - 1), sol[:, 1] * (gridSize - 1), np.cos(sol[:,2]), np.sin(sol[:,2]), color=\"purple\", scale=8.0, width=0.015, alpha=0.9)\n",
    "                    ax1.scatter(start[0] * (gridSize - 1), start[1] * (gridSize - 1), color=\"red\", s=250, edgecolors='black') # init\n",
    "                    ax1.scatter(goal[0] * (gridSize - 1), goal[1] * (gridSize - 1), color=\"blue\", s=250, edgecolors='black') # goal\n",
    "                    plt.show()\n",
    "            else:\n",
    "                nIterations = np.array([0, 0])\n",
    "                nCompletedTests -= 1\n",
    "                break \n",
    "        else:\n",
    "            nIterations = np.array([0, 0])\n",
    "            nCompletedTests -= 1\n",
    "            break\n",
    "    \n",
    "    nTotIterations += nIterations\n",
    "    nCompletedTests += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average # of iterations:  [ 61. 330.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Average # of iterations: \", nTotIterations / nTests)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9e6cc1179d3ed6ae143ff3dc9ac563dc8e696a51d4136aae17def4ab6c30aa1f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('project_env_3_8': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
