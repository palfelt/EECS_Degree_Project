{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Workspace problem with several narrow gaps\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules import loss\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "cuda = True\n",
    "DEVICE = torch.device(\"cuda\" if cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# neural network parameters\n",
    "mb_size = 256 # mini batch dim\n",
    "h_Q_dim = 512 # encoder dim\n",
    "h_P_dim = 512 # decoder dim\n",
    "\n",
    "c = 0 # unsure of this constant\n",
    "lr = 1e-4 # learning rate\n",
    "\n",
    "# problem dimenc_dimsions\n",
    "nDrawnSamples = 1 # number of dependent samples to draw during smapling\n",
    "dim = 4 # (x, y, xdot, ydot)\n",
    "dataElements = nDrawnSamples * dim + 2 * dim # sample (4D), init (4D), goal (4D)\n",
    "\n",
    "z_dim = 2 # latent dim\n",
    "X_dim = dim*nDrawnSamples # samples dim\n",
    "y_dim = dim # reconstruction of the original point (unsused?)\n",
    "c_dim = dataElements - dim # dimension of conditioning variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25284\n"
     ]
    }
   ],
   "source": [
    "# read in data from .txt file, re-arrange to allow drawing multiple depedent samples\n",
    "\n",
    "filename = '/home/oscar_palfelt/MSc_thesis/EECS_Degree_Project/motion_planning/data/pathDataDifficult'\n",
    "rawdata = np.genfromtxt(filename, delimiter=',', dtype='d')\n",
    "_, pathsIdx = np.unique(rawdata[:,4:], axis=0, return_index=True)\n",
    "pathsIdx.sort()\n",
    "\n",
    "pathsLenghts = pathsIdx[1:] - pathsIdx[:-1]\n",
    "validLengthsIdx = np.argwhere(pathsLenghts >= nDrawnSamples)\n",
    "validPlansIdx = pathsIdx[validLengthsIdx]\n",
    "\n",
    "data = np.zeros(shape=(1, dim*nDrawnSamples + dim*2))\n",
    "\n",
    "for c, i in enumerate(validPlansIdx.reshape(-1)):\n",
    "    rndSample = np.random.choice(np.arange(pathsLenghts[c]), size=(np.floor(pathsLenghts[c] / nDrawnSamples).astype(int), nDrawnSamples), replace=False)\n",
    "    rndSample.sort(axis=1)\n",
    "\n",
    "    for sample in rndSample:\n",
    "        data = np.vstack((data,np.append(rawdata[i + sample, :4].reshape(1, dim*nDrawnSamples), rawdata[i, 4:].reshape(1, dim*2), axis=1))) \n",
    "\n",
    "numEntries = data.shape[0]\n",
    "print(numEntries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the inputs and conditions into test train (to be processed in the next step into an occupancy grid representation)\n",
    "ratioTestTrain = 0.8;\n",
    "numTrain = int(numEntries*ratioTestTrain)\n",
    "\n",
    "X_train = data[0:numTrain,0:dim*nDrawnSamples] # samples state: x, y, xdot, ydot\n",
    "c_train = data[0:numTrain,dim*nDrawnSamples:dataElements] # conditions: gaps, init (4), goal (4)\n",
    "\n",
    "X_test = data[numTrain:numEntries,0:dim*nDrawnSamples]\n",
    "numTest = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate conditioning variable\n",
    "filename = '/home/oscar_palfelt/MSc_thesis/EECS_Degree_Project/motion_planning/data_generation/map_difficult.png'\n",
    "mapImg = cv2.imread(filename, 0)\n",
    "occGrid = np.clip(mapImg, 0, 1)\n",
    "\n",
    "assert occGrid.shape[0] == occGrid.shape[1]\n",
    "gridSize = occGrid.shape[0]\n",
    "\n",
    "conditionsOcc = np.tile(occGrid.reshape(1, gridSize ** 2), reps=(numEntries,1))\n",
    "    \n",
    "#cs = np.concatenate((data[0:numEntries,dim:dataElements], conditionsOcc), axis=1) # init (4D), goal (4D), occ(30x30)\n",
    "cs = data[0:numEntries,dim:dataElements]\n",
    "c_dim = cs.shape[1]\n",
    "c_train = cs[0:numTrain,:] \n",
    "c_test = cs[numTrain:numEntries,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pytorch networks\n",
    "# based on https://github.com/Jackson-Kang/Pytorch-VAE-tutorial/blob/master/.ipynb_checkpoints/01_Variational_AutoEncoder-checkpoint.ipynb\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim=X_dim+c_dim, hidden_dim=h_Q_dim, latent_dim=z_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.z_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.z_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        seq = self.network(x)\n",
    "\n",
    "        return self.z_mu(seq), self.z_logvar(seq)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=z_dim+c_dim, hidden_dim=h_P_dim, output_dim=X_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return self.network(x)\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, Encoder, Decoder):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.Encoder = Encoder\n",
    "        self.Decoder = Decoder\n",
    "    \n",
    "    def reparameterization(self, mean, logvar):\n",
    "        epsilon = torch.randn_like(mean).to(DEVICE)        # sampling epsilon        \n",
    "        z = mean + torch.exp(0.5 * logvar) * epsilon       # reparameterization trick\n",
    "        return z\n",
    "\n",
    "    def forward(self, x, c, encode=True):\n",
    "        if encode:\n",
    "            z_mu, z_logvar = self.Encoder(torch.cat((x, c), dim=1))\n",
    "            z = self.reparameterization(z_mu, z_logvar)\n",
    "\n",
    "            y = self.Decoder(torch.cat((z, c), dim=1))\n",
    "            \n",
    "            return y, z_mu, z_logvar\n",
    "        else:\n",
    "            z = x\n",
    "            y = self.Decoder(torch.cat((z, c), dim=1))    \n",
    "\n",
    "            return y\n",
    "\n",
    "\n",
    "encoder = Encoder()\n",
    "decoder = Decoder()\n",
    "network = NeuralNetwork(Encoder=encoder, Decoder=decoder).to(DEVICE)\n",
    "\n",
    "weight = torch.tensor([1, 1, 0.5, 0.5], requires_grad=False, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "def loss_function(x, y, mean, logvar):\n",
    "    recon_loss = (weight.repeat(1, nDrawnSamples) * (x - y) ** 2).mean()\n",
    "    kl_loss    = 10**-4 * 2 * torch.sum(torch.exp(logvar) + mean.pow(2) - 1. - logvar, dim=1)\n",
    "\n",
    "    return torch.mean(kl_loss + recon_loss)\n",
    "\n",
    "optimizer = optim.Adam(network.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "for it in range(200001):\n",
    "    # randomly generate batches\n",
    "    batch_elements = [np.random.randint(0,numTrain-1) for n in range(0,mb_size)]\n",
    "\n",
    "    X_mb = torch.tensor(X_train[batch_elements,:], requires_grad=True, dtype=torch.float32, device=DEVICE)\n",
    "    c_mb = torch.tensor(c_train[batch_elements,:], requires_grad=True, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    y, z_mu, z_logvar = network(X_mb, c_mb)\n",
    "    \n",
    "    loss = loss_function(X_mb, y, z_mu, z_logvar)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if it % 1000 == 0:\n",
    "        print('Iter: {}'.format(it))\n",
    "        print('Loss: {:.4}'. format(loss))\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the latent space\n",
    "\n",
    "num_viz = 3000 # number of samples to draw in latent space\n",
    "vizIdx = np.random.randint(0,numTest-1); # chose a random test scenario\n",
    "c_sample_seed = c_test[vizIdx,:]\n",
    "c_sample = torch.from_numpy(np.repeat([c_sample_seed],num_viz,axis=0)).float().to(DEVICE)\n",
    "\n",
    "y_viz = network(torch.randn(num_viz, z_dim).to(DEVICE), c_sample, encode=False).cpu().detach().numpy() # y_viz is sample in state space, zviz in latent space (3D)\n",
    "\n",
    "fig1 = plt.figure(figsize=(8,8), dpi=80)\n",
    "color = plt.cm.rainbow(np.linspace(0, 1, nDrawnSamples))\n",
    "for i in range(nDrawnSamples):\n",
    "    plt.scatter(y_viz[:,0 + i*dim] * gridSize, y_viz[:,1 + i*dim] * gridSize, color=color[i], s=70, alpha=0.1)\n",
    "plt.scatter(c_test[vizIdx, 0] * gridSize, c_test[vizIdx, 1] * gridSize, color=\"red\", s=250, edgecolors='black') # init\n",
    "plt.scatter(c_test[vizIdx, 4] * gridSize, c_test[vizIdx, 5] * gridSize, color=\"blue\", s=250, edgecolors='black') # goal\n",
    "plt.imshow(mapImg, extent=[0, gridSize, 0, gridSize], cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "64b15a9dfc037f101e6686cd2beac8a44adf976402fd7d9f80c174bf7ce5b31d"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
